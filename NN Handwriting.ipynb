{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(888)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(404)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "NR_CLASSES =10\n",
    "VALIDATION_SIZE =10000\n",
    "IMAGE_HT = 28\n",
    "IMAGE_WD = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUTS = IMAGE_HT*IMAGE_WD*CHANNELS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data and split into Xtrain ytrain Xtest and ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file ='mnist_train.csv'\n",
    "test_file ='mnist_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt(train_file, delimiter = ',', dtype=int,skiprows=0,usecols=range(1,785))\n",
    "X_test = np.loadtxt(test_file, delimiter = ',', dtype=int,skiprows=0,usecols=range(1,785)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.loadtxt(train_file, delimiter = ',', dtype=int,skiprows=0,usecols=0)\n",
    "y_test = np.loadtxt(test_file, delimiter = ',', dtype=int,skiprows=0,usecols=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert labels to dense matrix\n",
    "y_train = np.eye(NR_CLASSES)[y_train]\n",
    "y_test = np.eye(NR_CLASSES)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test  = X_train/255.0, X_test/255.0 #values between 0 and 1 for easy input to neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Validation set of 10000 images from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[:VALIDATION_SIZE]\n",
    "y_val = y_train[:VALIDATION_SIZE]\n",
    "\n",
    "X_train = X_train[VALIDATION_SIZE:]\n",
    "y_train = y_train[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a TensorFlow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape=[None,TOTAL_INPUTS],name= 'X')\n",
    "y = tf.placeholder(tf.float32,shape=[None,NR_CLASSES], name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_epochs = 25\n",
    "learning_rate = 0.0001\n",
    "\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the loss function, optimizer and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer 1\n",
    "\n",
    "initial_w1 = tf.truncated_normal(shape=[TOTAL_INPUTS,n_hidden1],stddev=0.1,seed=42)\n",
    "w1 = tf.Variable( initial_value = initial_w1,name='w1')\n",
    "initial_b1 = tf.constant(value =0.0, shape=[n_hidden1])\n",
    "b1 = tf.Variable(initial_value = initial_b1, name ='b1')\n",
    "\n",
    "layer1_in = tf.matmul(X,w1)+b1\n",
    "layer1_out = tf.nn.relu(layer1_in) #activation function is relu\n",
    "\n",
    "#Layer2\n",
    "\n",
    "initial_w2 = tf.truncated_normal(shape=[n_hidden1,n_hidden2], stddev =0.1, seed=42)\n",
    "w2 = tf.Variable(initial_value=initial_w2, name ='w2')\n",
    "\n",
    "initial_b2 = tf.constant(value=0.0,shape=[n_hidden2])\n",
    "b2 = tf.Variable(initial_value=initial_b2, name='b2')\n",
    "\n",
    "layer2_in = tf.matmul(layer1_out,w2)+b2\n",
    "layer2_out = tf.nn.relu(layer2_in)\n",
    "\n",
    "#Output layer\n",
    "initial_w3 = tf.truncated_normal(shape=[n_hidden2,NR_CLASSES], stddev =0.1, seed=42)\n",
    "w3 = tf.Variable(initial_value=initial_w3, name ='w3')\n",
    "\n",
    "initial_b3 = tf.constant(value=0.0,shape=[NR_CLASSES])\n",
    "b3 = tf.Variable(initial_value=initial_b3, name='b3')\n",
    "\n",
    "layer3_in = tf.matmul(layer2_out,w3)+b3\n",
    "output = tf.nn.softmax(layer3_in)  #function used is softmax to output values between 0 an 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = output)) ##Loss function..run inn batches..so take average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer and minimize loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy metric\n",
    "correct_pred = tf.equal(tf.argmax(output,axis=1),tf.argmax(y,axis=1)) #compare labels in tensor and output from Neural network\n",
    "#10 values in each row having probability between 0 1n 1..chose the highest one as the label output\n",
    "metric = tf.reduce_mean(tf.cast(correct_pred,tf.float32)) #take mean value and typecast as float as output is in decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Session and initialize values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess= tf.Session() #Create a Session\n",
    "init = tf.global_variables_initializer() #initialize variables\n",
    "sess.run(init) #Run the session to evaluate the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.eval(sess)\n",
    "\n",
    "b1.eval(sess) #512 values\n",
    "b2.eval(sess) #64 values\n",
    "b3.eval(sess) #10 values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000 #run 50000 examples in batches of 1000\n",
    "num_of_examples = y_train.shape[0] #50000 examples\n",
    "nr_of_iterations = int(num_of_examples/batch_size) #50000/1000\n",
    "index_in_epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a batch function\n",
    "\n",
    "def next_batch(batch_size,data,labels):\n",
    "    \n",
    "    global num_of_examples\n",
    "    global index_in_epoch\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > num_of_examples:\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "    \n",
    "    end = index_in_epoch\n",
    "    \n",
    "    return data[start:end], labels[start:end]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 0  \t| Training Accuracy is [0.638]\n",
      "             \t| validation accuracy is [0.6263]\n",
      "Epochs 1  \t| Training Accuracy is [0.804]\n",
      "             \t| validation accuracy is [0.7723]\n",
      "Epochs 2  \t| Training Accuracy is [0.845]\n",
      "             \t| validation accuracy is [0.8128]\n",
      "Epochs 3  \t| Training Accuracy is [0.86]\n",
      "             \t| validation accuracy is [0.8314]\n",
      "Epochs 4  \t| Training Accuracy is [0.872]\n",
      "             \t| validation accuracy is [0.8402]\n",
      "Epochs 5  \t| Training Accuracy is [0.876]\n",
      "             \t| validation accuracy is [0.8454]\n",
      "Epochs 6  \t| Training Accuracy is [0.879]\n",
      "             \t| validation accuracy is [0.8491]\n",
      "Epochs 7  \t| Training Accuracy is [0.881]\n",
      "             \t| validation accuracy is [0.8523]\n",
      "Epochs 8  \t| Training Accuracy is [0.882]\n",
      "             \t| validation accuracy is [0.8552]\n",
      "Epochs 9  \t| Training Accuracy is [0.884]\n",
      "             \t| validation accuracy is [0.8581]\n",
      "Epochs 10  \t| Training Accuracy is [0.885]\n",
      "             \t| validation accuracy is [0.86]\n",
      "Epochs 11  \t| Training Accuracy is [0.904]\n",
      "             \t| validation accuracy is [0.8771]\n",
      "Epochs 12  \t| Training Accuracy is [0.957]\n",
      "             \t| validation accuracy is [0.9186]\n",
      "Epochs 13  \t| Training Accuracy is [0.964]\n",
      "             \t| validation accuracy is [0.9277]\n",
      "Epochs 14  \t| Training Accuracy is [0.966]\n",
      "             \t| validation accuracy is [0.9317]\n",
      "Epochs 15  \t| Training Accuracy is [0.969]\n",
      "             \t| validation accuracy is [0.9351]\n",
      "Epochs 16  \t| Training Accuracy is [0.972]\n",
      "             \t| validation accuracy is [0.938]\n",
      "Epochs 17  \t| Training Accuracy is [0.972]\n",
      "             \t| validation accuracy is [0.939]\n",
      "Epochs 18  \t| Training Accuracy is [0.972]\n",
      "             \t| validation accuracy is [0.9402]\n",
      "Epochs 19  \t| Training Accuracy is [0.972]\n",
      "             \t| validation accuracy is [0.9421]\n",
      "Epochs 20  \t| Training Accuracy is [0.974]\n",
      "             \t| validation accuracy is [0.9431]\n",
      "Epochs 21  \t| Training Accuracy is [0.974]\n",
      "             \t| validation accuracy is [0.9451]\n",
      "Epochs 22  \t| Training Accuracy is [0.975]\n",
      "             \t| validation accuracy is [0.9456]\n",
      "Epochs 23  \t| Training Accuracy is [0.974]\n",
      "             \t| validation accuracy is [0.9462]\n",
      "Epochs 24  \t| Training Accuracy is [0.974]\n",
      "             \t| validation accuracy is [0.9475]\n",
      "Done Training!!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nr_epochs):\n",
    "    \n",
    "    #=============training data set==================\n",
    "    \n",
    "    for i in range(nr_of_iterations):\n",
    "        batch_x,batch_y = next_batch(batch_size=batch_size,data=X_train,labels=y_train)\n",
    "        \n",
    "        feed_dictionary = {X:batch_x, y: batch_y}\n",
    "        sess.run(train_step,feed_dict=feed_dictionary)\n",
    "       \n",
    "        batch_accuracy = sess.run(fetches=[metric], feed_dict=feed_dictionary)\n",
    "              \n",
    "    print(f'Epochs {epoch}  \\t| Training Accuracy is {batch_accuracy}')\n",
    "    \n",
    "     #=================Validation dataset =================  \n",
    "    validation_accuracy = sess.run(fetches=[metric],feed_dict = {X:X_val,y:y_val})\n",
    "    print(f'             \\t| validation accuracy is {validation_accuracy}')\n",
    "    \n",
    "print('Done Training!!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAADAUlEQVR4nO2WvUsrTRTGn8nOJmA2foDET9RwrdaLlZWFIEYsBCuxEkQbtbHyLxAUCwuLiIVl+mBECIitXwiiiNgEi4AoEWICIcbdnX1uc2+u4jWJ8JrqfWCqmXN+zJxnzowoFAqUUqIWchwHUkoJXddrAgQAT81I/wM/k1IK2WwW2WwWmUwGGxsbWFlZwezsLFKpFGZmZhAMBtHb24tIJPIhvqI9Hx4eUCwWcX5+juPjYzw9PSGRSJTmi8UiAKClpQXLy8vY29uDz+dDZ2cn+vv7P+QTlmXxM5fe3NxgYmIC6XQaSikopUAStm2/W+fz+RCJRGAYBlzXRWtrK5qbm9HX1wdN00rrbNsGLMviZ8pkMjR/mhRCEMC7MTAwwOHhYXq9XgaDQTqOUxpKKbqu+yGfZVksCyTJ3d1dzs3NcXNzk7quEwBN02Qul6NlWby4uODCwkLZHF8CKqWYy+XoOA7n5+cppWQ0Gi3Nu65Lx3GqBlZ0qcfjQX19PTRNQ2NjI0hiZ2fnrwmEeFeniqq0w7fK5/McGhqiEIKHh4dVx73d4ZeAJHl3d0e/38+2tjZOT09ze3v7e4EkGYvFGAgEKISgrutcX1/n4+Pj9wFJ8vr6muFwmLqu0+v1cmlpiff3998HJMnn52dGo1ECoJSS4+PjVEp9D/DPdXh5eaGmaQTApqYmHh0dlQV++ann79Z2dXWFWCyGs7MzKKXg8XhgmiYGBwfLxlcN/AO6vb3F1tYW4vE40uk0AEDTNBiGgZ6ensqJKh2p67q0bZvJZJJra2vs6uoq9VNN02gYBkdHR3lwcFCxDGVr6Lou8/k8k8kk4/E4TfNvE5dSMhAIcGRkhPv7+xVBZYG2bTOfzzOVSnFqaoqhH6ESSAjBuro6hsNhJhIJvr6+Vg37FHh6esrJyUl2dHRQCEEpJf1+Pw3DYHd3N1dXV1koFL4Eegv8YJqTkxNcXl4CANrb2xEKhTA2NgYpJRYXF9HQ0FCtz/6psi/+fy3btmv/a5OO49QM5jgOfgFskn3Kzt/jewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=28x28 at 0x19BA83445C0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('D:/Data/Downloads/5.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABT0lEQVR4nK3SuUsDQRgF8DfZ2QTMxgMknnhhlYCVlYUgRiwEK7ESRBu1sfIvEBQLC4uIhWX6YEQIiK0XgigiNsEiIEqEmECIcXdmP4tcm2OsfN3wm+LN8FieQxXBua5EuNT0bygzmfT+9kpy2T8aBoBK1/fC3dVnHCiga+vU0z8GAMwstn2eT0lJFgBP2LC7O4MaYMEkIiJKBxkAjE+5/UIIaRMRmWWkk9UDHYGseb9O5VRRZsUajxDZooqVtq5WrZ2OAaY56puVi5SbZBfkiOlEevX2LB2pkKI+pu99KJCeQrp7802B9BUBn5PN0RbfGjouS1izA7Ieo7fSFZgonbmTXg5jKWjGUMM7bSuxOwBoxsx5fVs7l4gFGLhv+qz+nVYuuTjCwFpC8Z+GH7pZ6GPcawzu5GuqF9teP6B3eJZvtNVtqLyEZrH+XB8XahO/ialaz+KspXUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x19BA8344748>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw = img.convert('L') #Convert color image to grey scale image\n",
    "bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array = np.invert(bw) #Covert bw image to ndarray\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = img_array.ravel() #flatten array with np.ravel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sess.run(fetches=tf.argmax(output,axis=1),feed_dict={X:[test_img]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for a test image is [5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Prediction for a test image is {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = sess.run(fetches= metric,feed_dict={X:X_test,y:y_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy is 94.76%\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction accuracy is {pred2:0.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
